{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpamDetection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQeyJ4G68h8+VBldROooll",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s10114618/Machine-Learning-NLP-Spam-Detector/blob/master/SpamDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0mkZTN9qZF_",
        "colab_type": "text"
      },
      "source": [
        "# Challenge\n",
        "In this challenge, we will use Natural Language Processing and Naive Bayes Classifier to detect spam. We will compare Naive Bayes with Logistic Regression to understand which is better for spam detection.\n",
        "\n",
        "\n",
        "### Concepts\n",
        "1. Try out Naive Bayes Classifier on another dataset and analyze the outcome\n",
        "2. Compare Naive Bayes against LogisticRegression\n",
        "\n",
        "### Useful Links\n",
        "[Email Dataset](http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/index.html) <br>\n",
        "[Supervised Classification](https://www.nltk.org/book/ch06.html)<br>\n",
        "[Feature Extraction](https://scikit-learn.org/stable/modules/feature_extraction.html) <br>\n",
        "[Lemmatization](https://www.machinelearningplus.com/nlp/lemmatization-examples-python/)<br>\n",
        "[NLP Vectorization](https://towardsdatascience.com/natural-language-processing-count-vectorization-with-scikit-learn-e7804269bb5e)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9QdGAVuqWi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports and additional functions which will be used for the Lab.\n",
        "from __future__ import print_function, division\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "import random\n",
        "import os\n",
        "import tarfile\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from collections import Counter\n",
        "from nltk import word_tokenize, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import NaiveBayesClassifier, classify"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ_tLlGYqq8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "2e83bc02-32df-47e8-d7fa-ce9c198de6bd"
      },
      "source": [
        "# Download ntlk data to working directory\n",
        "dirpath = os.getcwd()\n",
        "# Nltk is NLP tool kit\n",
        "nltk.data.path = [dirpath+'/nltk_data']\n",
        "nltk.download('stopwords', download_dir='nltk_data') #i me my myself we our ours\n",
        "nltk.download('punkt', download_dir='nltk_data') #\n",
        "nltk.download('wordnet', download_dir='nltk_data') #\n",
        "stoplist = stopwords.words('english')\n",
        "print(\"Print the length of Stoplist: \"+ str(len(stoplist)))\n",
        "print(\"Print some example of Stoplist: \" + str(stoplist[-5:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Print the length of Stoplist: 179\n",
            "Print some example of Stoplist: [\"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-oMBoNPq4W0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "54fb46bf-e3ee-465e-d3d4-3f37fb5619dc"
      },
      "source": [
        "# Download online Spam dataset\n",
        "import urllib.request\n",
        "import tarfile\n",
        "enron2_dataset_url = \"http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/preprocessed/enron2.tar.gz\"\n",
        "enron2_dataset_fileobj = urllib.request.urlopen(enron2_dataset_url)\n",
        "\n",
        "tf = tarfile.open(fileobj=enron2_dataset_fileobj, mode=\"r|gz\")\n",
        "tf.extractall(path=\".\")\n",
        "\n",
        "# Read each item in file and store into a List Object\n",
        "def init_lists(folder):\n",
        "    key_list = []\n",
        "    file_content = os.listdir(folder)\n",
        "    for a_file in file_content:\n",
        "        f = open(folder + a_file, 'r', encoding='cp437')\n",
        "        key_list.append(f.read())\n",
        "    f.close()\n",
        "    return key_list\n",
        "\n",
        "spam = init_lists('./enron2/spam/')\n",
        "ham = init_lists('./enron2/ham/')\n",
        "\n",
        "print(\"Print the length of Spam Messages: \"+ str(len(spam)))\n",
        "print(\"Print some example of Spam: \" + str((spam[10])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Print the length of Spam Messages: 1496\n",
            "Print some example of Spam: Subject: save your money buy getting this thing here\n",
            "you have not tried cialls yet ?\n",
            "than you cannot even imagine what it is like to be a real man in bed !\n",
            "the thing is that a great errrectlon is provided for you exactly when you want .\n",
            "ciails has a iot of advantaqes over viaqra\n",
            "- the effect lasts 36 hours !\n",
            "- you are ready to start within just 10 minutes !\n",
            "- you can mix it with aicohol ! we ship to any country !\n",
            "get it riqht now ! .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrQIjvpFrgTk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "39bfbad8-e9b0-4305-d23f-43382c4136b1"
      },
      "source": [
        "print(\"Print the length of ham Messages: \"+ str(len(ham)))\n",
        "print(\"Print some example of ham: \" + str((ham[10])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Print the length of ham Messages: 4361\n",
            "Print some example of ham: Subject: re : grades\n",
            "mr . kaminsky ,\n",
            "i still need grades for :\n",
            "israni , rakhi\n",
            "lu , feng\n",
            "planck , jeffrey\n",
            "so , winny\n",
            "taylor , orlando\n",
            "wankhade , sanjay\n",
            "zhang , ning\n",
            "i will be available by e - mail this evening or by phone ( 5 : 30 or so ) at\n",
            "713 - 668 - 1704 . ? i just called the registrar ' s office and if i bring in the\n",
            "grades by 8 : 30 tomorrow morning we will be fine . ? please advise .\n",
            "thanks for your help . - pam\n",
            "at 08 : 23 am 5 / 4 / 01 - 0500 , vince . j . kaminski @ enron . com wrote :\n",
            "pam ,\n",
            "the last group .\n",
            "please , let me know if any name is missing .\n",
            "( embedded image moved to file : pic 25177 . pcx )\n",
            "grade : a\n",
            "thanks a lot . it was a pleasure working with you .\n",
            "vince kaminski\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t03U2BP0rnx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df9a5741-1328-4c18-a450-c30c7b329106"
      },
      "source": [
        "all_mails = [(mail, 'spam') for mail in spam]\n",
        "all_mails += [(mail, 'ham') for mail in ham]\n",
        "print ('Corpus of size = ' + str(len(all_mails)) + ' mails')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus of size = 5857 mails\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9r7mELIrqbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9328ad67-8dd0-4f69-dc8e-5ae145b3171c"
      },
      "source": [
        "## Tokenise sentences into word/char\n",
        "def get_features(text, setting):\n",
        "    if setting=='bow':\n",
        "        return {word: count for word, count in Counter(preprocess(text)).items() if not word in stoplist}\n",
        "    else:\n",
        "        return {word: True for word in preprocess(text) if not word in stoplist}\n",
        "\n",
        "def preprocess(sentence):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(word.lower()) for word in word_tokenize(sentence)]\n",
        "\n",
        "all_features = [(get_features(mail, ''), label) for (mail, label) in all_mails]\n",
        "print ('Fetched ' + str(len(all_features)) + ' feature sets')\n",
        "print(\"Example of tokenized word/char: \"+str(all_features[0:1][0:5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetched 5857 feature sets\n",
            "Example of tokenized word/char: [({'subject': True, ':': True, 'returned': True, 'mail': True, 'message': True, 'sent': True, 'could': True, 'delivered': True, '.': True, 'original': True, 'wa': True, 'received': True, '19': True, 'jul': True, '2005': True, '10': True, '57': True, '00': True, '+': True, '0100': True, '?': True, '-': True, 'following': True, 'address': True, 'delivery': True, 'problem': True, '(': True, 'permanent': True, 'unrecoverable': True, 'error': True, ')': True, 'diese': True, 'e': True, 'enthσlt': True, 'vertrauliche': True, 'und': True, '/': True, 'oder': True, 'rechtlich': True, 'geschⁿtzte': True, 'informationen': True, 'wenn': True, 'sie': True, 'nicht': True, 'der': True, 'richtige': True, 'adressat': True, 'sind': True, 'irrtⁿmlich': True, 'erhalten': True, 'haben': True, ',': True, 'informieren': True, 'bitte': True, 'sofort': True, 'den': True, 'absender': True, 'vernichten': True, 'da': True, 'unerlaubte': True, 'kopieren': True, 'sowie': True, 'die': True, 'unbefugte': True, 'weitergabe': True, 'dieser': True, 'ist': True, 'gestattet': True, 'may': True, 'contain': True, 'confidential': True, 'privileged': True, 'information': True, 'intended': True, 'recipient': True, 'please': True, 'notify': True, 'sender': True, 'immediately': True, 'destroy': True, 'unauthorized': True, 'copying': True, 'disclosure': True, 'distribution': True, 'material': True, 'strictly': True, 'forbidden': True}, 'spam')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf5-rvYgsPvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ecbec3e0-d09f-4f96-f604-28f3ba426822"
      },
      "source": [
        "def train(features, samples_proportion):\n",
        "    train_size = int(len(features) * samples_proportion)\n",
        "    # initialise the training and test sets\n",
        "    train_set, test_set = features[:train_size], features[train_size:]\n",
        "    print ('Training set of size= ' + str(len(train_set)) + ' mails')\n",
        "    print ('Test set of size = ' + str(len(test_set)) + ' mails')\n",
        "    # train the classifier\n",
        "    classifier = NaiveBayesClassifier.train(train_set)\n",
        "    nbc_accuracy = classify.accuracy(classifier, test_data) * 100\n",
        "    return train_set, test_set, classifier, nbc_accuracy\n",
        "\n",
        "# train the classifier and get the training and test dataset\n",
        "train_set, test_set, classifier, nbc_accuracy = train(all_features, 0.8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set of size= 4685 mails\n",
            "Test set of size = 1172 mails\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDaZgDnPs8b2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "fd4bfe5b-cade-4ebf-acbb-6ab8a0a823b8"
      },
      "source": [
        "def evaluate(train_set, test_set, classifier):\n",
        "    # test accuracy of classifier on training and test set\n",
        "    print ('Training set accuracy = ' + str(classify.accuracy(classifier, train_set)))\n",
        "    print ('Test set accuracy = ' + str(classify.accuracy(classifier, test_set)))\n",
        "    # check most informative words for the classifier\n",
        "    classifier.show_most_informative_features(20)\n",
        "\n",
        "# evaluate performance\n",
        "evaluate(train_set, test_set, classifier)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set accuracy = 0.9980789754535753\n",
            "Test set accuracy = 0.9982935153583617\n",
            "Most Informative Features\n",
            "                   vince = True              ham : spam   =    635.6 : 1.0\n",
            "                     hou = True              ham : spam   =    338.4 : 1.0\n",
            "                     ect = True              ham : spam   =    215.4 : 1.0\n",
            "                 shirley = True              ham : spam   =    167.2 : 1.0\n",
            "                      cc = True              ham : spam   =    162.6 : 1.0\n",
            "                     713 = True              ham : spam   =    150.6 : 1.0\n",
            "                     oem = True             spam : ham    =     90.2 : 1.0\n",
            "                     853 = True              ham : spam   =     89.3 : 1.0\n",
            "              macromedia = True             spam : ham    =     87.4 : 1.0\n",
            "               forwarded = True              ham : spam   =     85.5 : 1.0\n",
            "                     php = True             spam : ham    =     81.7 : 1.0\n",
            "                   woman = True             spam : ham    =     80.3 : 1.0\n",
            "                    2005 = True             spam : ham    =     72.6 : 1.0\n",
            "                   kevin = True              ham : spam   =     69.0 : 1.0\n",
            "                 artwork = True             spam : ham    =     66.1 : 1.0\n",
            "                   corel = True             spam : ham    =     61.8 : 1.0\n",
            "                      eb = True              ham : spam   =     60.5 : 1.0\n",
            "                     doc = True              ham : spam   =     60.0 : 1.0\n",
            "                    8859 = True             spam : ham    =     59.0 : 1.0\n",
            "                 houston = True              ham : spam   =     56.9 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxFrIB5_tmDe",
        "colab_type": "text"
      },
      "source": [
        "#Same dataset, different model - Logistic Regression model accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEL660zytu_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a01596e8-a1f0-4738-8e7d-c48d426727e4"
      },
      "source": [
        "df_mails = pd.DataFrame(all_features, columns=['words','label'])\n",
        "df_mails.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'subject': True, ':': True, 'returned': True,...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'subject': True, ':': True, 'esecure': True, ...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'subject': True, ':': True, 'online': True, '...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'subject': True, ':': True, 'free': True, 'st...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'subject': True, ':': True, 'catalogue': True...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               words label\n",
              "0  {'subject': True, ':': True, 'returned': True,...  spam\n",
              "1  {'subject': True, ':': True, 'esecure': True, ...  spam\n",
              "2  {'subject': True, ':': True, 'online': True, '...  spam\n",
              "3  {'subject': True, ':': True, 'free': True, 'st...  spam\n",
              "4  {'subject': True, ':': True, 'catalogue': True...  spam"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIxn4VmMt2Fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit the dataframe column into the Vectorizer and get feature names\n",
        "dictVectorizer = DictVectorizer()\n",
        "train_data_dict = dictVectorizer.fit_transform(df_mails['words'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBjTNB0Ot5BR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Following the train function for Naive Bayes, use the first 80% to train, next 20% to test. \n",
        "split_size = round(df_mails.shape[0] * 0.8)\n",
        "\n",
        "# Get the features and result columns\n",
        "att = train_data_dict\n",
        "res = df_mails['label']\n",
        "\n",
        "# Split training data\n",
        "train_att = att[:split_size]\n",
        "train_res = res[:split_size]\n",
        "\n",
        "# Split testing data\n",
        "test_att = att[split_size:]\n",
        "test_res = res[split_size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EJkTnrruFGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6a663d9-0955-47ba-b2f3-f00725510fc7"
      },
      "source": [
        "# Do LogisticRegression\n",
        "clf = LogisticRegression()\n",
        "clf.fit(train_att, train_res)\n",
        "pred = clf.predict(test_att)\n",
        "lr_accuracy = 100.0 * accuracy_score(test_res, pred)\n",
        "print(\"LR accuracy: \" + str(lr_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR accuracy: 99.1460290350128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlECFfHnuR-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "290f5682-62b0-47de-cad4-2d5d32da46c8"
      },
      "source": [
        "## Final comparison\n",
        "print(\"NB: \" + str(nbc_accuracy) + \"\\nLR: \" + str(lr_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NB: 99.57337883959045\n",
            "LR: 99.1460290350128\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}